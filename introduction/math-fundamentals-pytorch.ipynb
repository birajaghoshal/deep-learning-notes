{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematics Fundamentals with PyTorch\n",
    "\n",
    "In this notebook we will explore some mathematical notions required for understanding deep learning not by theorems and text but rather with code , we will demonstrate using [PyTorch](http://pytorch.org/) ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epilogue\n",
    "\n",
    "Deep Learning uses a lot of mathematical concepts from different fields Matrix Operations from *Linear Algebra* , Derivatives and Optimization from *Real Analysis* , Density Functions,Distributions from *Probability Theory* if you are interested in doing cutting edge research a mastery of these would be required but we're more interested in the Hacker's way where we understand the concepts and use them to engineer our projects and apply Machine Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch\n",
    "\n",
    "PyTorch is a Deep Learning framework or library like [TensorFlow](www.tensorflow.org) or [Caffe2](https://caffe2.ai) it provides primitives like Linear Algebra operations,optimization ... to be able to build Neural Networks,these are represented in the form of Graphs called computational graphs ,where operations are represented in form of a graph ![computationalgraph](https://colah.github.io/posts/2015-08-Backprop/img/tree-def.png) .\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Algebra with PyTorch\n",
    "\n",
    "PyTorch can replace NumPy and you can use it with a GPU for massive improvements over performance ,for an indepth numerical algebra course check [fast.ai numerical linear algbera ](https://github.com/fastai/numerical-linear-algebra)\n",
    "\n",
    "#### Matrtix Tensors and NEO\n",
    "\n",
    "A Vector v is a a 1-dimensional array of numbers , a Matrix is 2-dimensional array of numbers, a Tensor well a Tensor is an n-dimensional array of numbers , tensors describe linear relations between geometric spaces think of them as buckets of numbers .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.00000e-02 *\n",
      " -1.3144  0.0000 -1.3144\n",
      "  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000\n",
      "[torch.FloatTensor of size 5x3]\n",
      " \n",
      "-1.3144e-02\n",
      " 4.5560e-41\n",
      " 2.7836e-37\n",
      "[torch.FloatTensor of size 3]\n",
      " \n",
      "(0 ,.,.) = \n",
      " -1.3145e-02  4.5560e-41 -1.3145e-02\n",
      "  4.5560e-41  1.8217e-44  4.1058e-42\n",
      "  1.0511e-39  4.6608e-32  2.5353e+30\n",
      "\n",
      "(1 ,.,.) = \n",
      "  1.6816e-44  3.6371e+27  1.1866e+27\n",
      "  1.1422e-40  3.1407e-24  1.5046e-36\n",
      "  9.9402e-32  9.4780e-38  9.4780e-38\n",
      "\n",
      "(2 ,.,.) = \n",
      "  9.4780e-38  3.9729e-34  1.4708e-39\n",
      "  5.0782e+31  2.2561e-43  0.0000e+00\n",
      " -1.3145e-02  4.5560e-41 -1.3145e-02\n",
      "[torch.FloatTensor of size 3x3x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting Started with PyTorch\n",
    "\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "\n",
    "##Tensor Constructions \n",
    "x = torch.Tensor(5,3) #constructing a 5x3 Matrix\n",
    "y = torch.Tensor(3) #constructing a vector \n",
    "z = torch.Tensor(3,3,3) #constructing a 3-d tensor \n",
    "\n",
    "print(x,y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0 ,.,.) = \n",
      "1.00000e-04 *\n",
      "   1.7278  0.0000  1.7278\n",
      "   0.0000  0.0000  0.0000\n",
      "   0.0000  0.0000  0.0000\n",
      "\n",
      "(1 ,.,.) = \n",
      "1.00000e-04 *\n",
      "   0.0000  0.0000  0.0000\n",
      "   0.0000  0.0000  0.0000\n",
      "   0.0000  0.0000  0.0000\n",
      "\n",
      "(2 ,.,.) = \n",
      "1.00000e-04 *\n",
      "   0.0000  0.0000  0.0000\n",
      "   0.0000  0.0000  0.0000\n",
      "  -0.0000  0.0000 -0.0000\n",
      "[torch.FloatTensor of size 3x3x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Numerical Operations can be run on tensors \n",
    "a = torch.Tensor(3,3,3)\n",
    "print(a*z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning methods like Topic Modeling,Recommender systems uses extensive Matrix Decompositions like SVD for example (Non Negative Matrix Factorization...), PCA for example can be used for different things like Background noise removal or Feature Reduction for Visualization .\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'torch.FloatTensor' object has no attribute 'uniform'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d6af57fafb2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'torch.FloatTensor' object has no attribute 'uniform'"
     ]
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       " -0.3976  0.8140  0.4234\n",
       " -0.7138  0.0156 -0.7002\n",
       " -0.5766 -0.5807  0.5748\n",
       " [torch.FloatTensor of size 3x3], \n",
       "  1.7103\n",
       "  0.6783\n",
       "  0.3554\n",
       " [torch.FloatTensor of size 3], \n",
       " -0.6871 -0.5968 -0.4144\n",
       " -0.6337  0.7713 -0.0600\n",
       " -0.3555 -0.2214  0.9081\n",
       " [torch.FloatTensor of size 3x3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(3,3)\n",
    "a.svd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.5644  0.7086  0.6762\n",
      " 0.5857  0.5998  0.6093\n",
      " 0.6172  0.5999  0.6642\n",
      "[torch.FloatTensor of size 3x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logistic regression Sigmoid(W*X+b)\n",
    "b = torch.rand(3)\n",
    "W = torch.rand(3,3)\n",
    "X = torch.rand(3,3)\n",
    "\n",
    "L = torch.sigmoid(W*X+b)\n",
    "print(L)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograd\n",
    "\n",
    "Autograd is a package that provides automatic differentiation in other words given f(x) it can compute the derivative df(x) .\n",
    "\n",
    "This can be done in different ways for example we can use reverse mode differentiation (diff)[https://stats.stackexchange.com/questions/224140/step-by-step-example-of-reverse-mode-automatic-differentiation] there also methods that leverage dual numbers in the form of z = a + b.epsilon where epsilon is nilpotent and epsilon^2 = 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(x,y)= x * x * y + y + 2\n",
      "f(3,4)= 42\n",
      "df/dx= 24.0\n",
      "df/dy= 10.0\n"
     ]
    }
   ],
   "source": [
    "# reverse mode differentiation\n",
    "class Const(object):\n",
    "    def __init__(self,value):\n",
    "        self.value = value\n",
    "    def evaluate(self):\n",
    "        return self.value\n",
    "    def backpropagate(self,gradient):\n",
    "        pass\n",
    "    def __str__(self):\n",
    "        return str(self.value)\n",
    "    \n",
    "class Var(object):\n",
    "    def __init__(self,init_value,name):\n",
    "        self.value = init_value\n",
    "        self.name = name\n",
    "        self.gradient = 0\n",
    "    def evaluate(self):\n",
    "        return self.value\n",
    "    def backpropagate(self,gradient):\n",
    "        self.gradient += gradient\n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "class BinaryOperator(object):\n",
    "    def __init__(self,a,b):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "class Add(BinaryOperator):\n",
    "    def evaluate(self):\n",
    "        self.value = self.a.evaluate() + self.b.evaluate()\n",
    "        return self.value\n",
    "    def backpropagate(self,gradient):\n",
    "        self.a.backpropagate(gradient)\n",
    "        self.b.backpropagate(gradient)\n",
    "    def __str__(self):\n",
    "        return \"{} + {}\".format(self.a,self.b)\n",
    "    \n",
    "class Mul(BinaryOperator):\n",
    "    def evaluate(self):\n",
    "        self.value = self.a.evaluate() * self.b.evaluate()\n",
    "        return self.value\n",
    "    def backpropagate(self,gradient):\n",
    "        self.a.backpropagate(gradient * self.b.value)\n",
    "        self.b.backpropagate(gradient * self.a.value)\n",
    "    def __str__(self):\n",
    "        return \"{} * {}\".format(self.a,self.b)\n",
    "    \n",
    "x = Var(3,name='x')\n",
    "y = Var(4,name='y')\n",
    "\n",
    "f = Add(Mul(Mul(x,x),y),Add(y,Const(2))) #f(x,y) = x^2y+2+2\n",
    "\n",
    "result = f.evaluate()\n",
    "#backpropagate takes the gradient of the output respect to the input dn7/df node which is one\n",
    "f.backpropagate(1.0)\n",
    "print(\"f(x,y)=\",f)\n",
    "print(\"f(3,4)=\",result)\n",
    "print(\"df/dx=\",x.gradient)\n",
    "print(\"df/dy=\",y.gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using pytorch autograd package\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "1.00000e+05 *\n",
      "     nan\n",
      "  0.0340\n",
      "  3.1644\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.Tensor([-1,3,4]),requires_grad=True)\n",
    "y = x**x + 3\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "out.backward()\n",
    "print(x.grad) #computes d(out)/dx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions\n",
    "\n",
    "Activation functions are principal components of neural networks they introduce non linearities in neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.Tensor(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.0000  0.5000  0.5000\n",
      " 0.5000  0.5000  0.5000\n",
      " 0.5000  0.5000  0.5000\n",
      "[torch.FloatTensor of size 3x3]\n",
      "\n",
      "\n",
      "-1.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000\n",
      "[torch.FloatTensor of size 3x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(x.sigmoid()) #sigmoid is defined as f(x) = 1 / 1 + e^-x\n",
    "print(x.tanh()) #tanh is the tangent hyperbolic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
